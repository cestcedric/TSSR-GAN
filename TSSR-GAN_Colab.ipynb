{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjKVC18uRQ_H"
      },
      "source": [
        "# TSSR-GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_5IUblkRVPT"
      },
      "source": [
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "## Setup\r\n",
        "1. Clone git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgGqLEge2xK2"
      },
      "source": [
        "! git clone https://github.com/cestcedric/TSSR-GAN.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJdZ_0kiRcWZ"
      },
      "source": [
        "2. Install required packages: these packages also contain packages for the metric computation and probably a few not necessary anymore. PyTorch version just has to be >= 1.4, but you have to match CUDA from PyTorch with the NVCC version. For Google Colab: manually restart runtime (bottom at the bottom of this output)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xS55QyM33Jp9"
      },
      "source": [
        "% cd /content/TSSR-GAN/\r\n",
        "! pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoI8WOqoSLc8"
      },
      "source": [
        "3. Compile PWCNet and DAIN modules (this is the part where the NVCC version is important, as execution using PyTorch will use the PyTorch version)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpcvrhTF6IcI"
      },
      "source": [
        "% cd /content/TSSR-GAN/\r\n",
        "! chmod +x scripts/setup.sh\r\n",
        "! scripts/setup.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95iDcnK2SYNE"
      },
      "source": [
        "4. Download the pretrained model weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoZwwiXHFeKj"
      },
      "source": [
        "% cd /content/TSSR-GAN\r\n",
        "! chmod +x scripts/getModelWeights.sh\r\n",
        "! scripts/getModelWeights.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRt6IB2aScP7"
      },
      "source": [
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "## Inference\r\n",
        "Add some sequence base frames and put them into this structure:\r\n",
        "```\r\n",
        "main_dir\r\n",
        "    sequence_1\r\n",
        "        start.png, end.png\r\n",
        "    sequence_2\r\n",
        "        start.png, end.png\r\n",
        "```\r\n",
        "\r\n",
        "Then start the super-resolution with:\r\n",
        "```\r\n",
        "! python3 interpolate.py \\\r\n",
        "--input_dir /path/to/main_dir/ \\\r\n",
        "--output_dir /path/to/results \\\r\n",
        "--weights model_weights/pretrained/best_GEN.pth \\\r\n",
        "--timestep 0.5\r\n",
        "```\r\n",
        "\r\n",
        "A time step of 0.5 means one intermediate frame, so start <-0.5-> intermediate <-0.5-> end. For 9 intermediate frames use time step = 1/(intermediate frames + 1) = 0.1.\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obr5ZUCuBge2"
      },
      "source": [
        "% cd /content/TSSR-GAN\r\n",
        "! python3 interpolate.py \\\r\n",
        "--input_dir /content/testdata/Adobe240/RESIZED/triplets/ \\\r\n",
        "--output_dir /content/results \\\r\n",
        "--weights model_weights/pretrained/best_GEN.pth \\\r\n",
        "--timestep 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kizmXjwTUXqq"
      },
      "source": [
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "## Training\r\n",
        "\r\n",
        "Don't train on Google Colab, unless you have a paid version or something, it takes way to long to get results before the automatic disconnection using the base version.\r\n",
        "\r\n",
        "Anyway, loads of parameters that can be set for training, see `utils/my_args.py` or use `!python3 train.py --help`.\r\n",
        "\r\n",
        "The training data can be saved randomly dispersed, all in one directory, whatever. BUT you have to provide a directory with `trainlist.txt` and `validlist.txt`, which look something like this for sequences with 3 frames:\r\n",
        "```\r\n",
        "seq1/frame1.png;seq1/frame2.png;seq1/frame3.png\r\n",
        "seq2/frame1.png;seq2/frame2.png;seq2/frame3.png\r\n",
        "seq3/frame1.png;seq3/frame2.png;seq3/frame3.png\r\n",
        "seq4/frame1.png;seq4/frame2.png;seq4/frame3.png\r\n",
        "seq5/frame1.png;seq5/frame2.png;seq5/frame3.png\r\n",
        "```\r\n",
        "\r\n",
        "Start training using:\r\n",
        "```\r\n",
        "! python3 train.py \\\r\n",
        "--pretrained_generator path/to/pretrained.pth \\\r\n",
        "--numEpoch 20 \\\r\n",
        "--lengthEpoch 5000 \\\r\n",
        "--datasetPath path/to/dataset \\\r\n",
        "--max_img_height 512 \\\r\n",
        "--max_img_width 512 \\\r\n",
        "--interpolationsteps 5 \\\r\n",
        "--improved_estimation 1 \\\r\n",
        "--gan \\\r\n",
        "--depth \\\r\n",
        "--flow \\\r\n",
        "--spatial \\\r\n",
        "--temporal \\\r\n",
        "--loss_pingpong \\\r\n",
        "--loss_layer \\\r\n",
        "--loss_perceptual \\\r\n",
        "--debug_output \\\r\n",
        "--tb_experiment training \\\r\n",
        "--debug_output_dir training_output/training \\\r\n",
        "--warmup_discriminator \\\r\n",
        "--warmup_boost 4 \\\r\n",
        "--no_cudnn_benchmark\r\n",
        "```\r\n",
        "\r\n",
        "Interpolationsteps denotes the newly generated intermediate frames, which means interpolationsteps = sequence length - 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA-LXI8oXgyk"
      },
      "source": [
        "\r\n",
        "\r\n",
        "---\r\n",
        "# ENJOY!\r\n",
        "\r\n"
      ]
    }
  ]
}